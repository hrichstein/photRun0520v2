{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MCMC FIT TO HST DATA INCLUDING BOTH ERI II AND CLUSTER, BINNED BY 30 PIXELS, AND MASKED \n",
    "#APPROPRIATELY\n",
    "#PLUMMER PROFILE FOR ERI II, SERSIC PROFILE FOR CLUSTER\n",
    "#UPDATED TO FIT ALL MODEL PARAMETERS INSTEAD OF JUST RICHNESS AND CENTER POSITION\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.path import Path\n",
    "from matplotlib.patches import PathPatch\n",
    "# from matplotlib.mlab import rec2csv\n",
    "\n",
    "import emcee\n",
    "import corner\n",
    "\n",
    "from astropy.io import ascii\n",
    "import _pickle as cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#READ IN PHOTOMETRY FROM AN ASCII FILE\n",
    "cat = ascii.read(\"eri2.cat\")  \n",
    "\n",
    "x=cat[cat.colnames[0]]\n",
    "y=cat[cat.colnames[1]]\n",
    "m606=cat[cat.colnames[2]]\n",
    "dm606=cat[cat.colnames[3]]\n",
    "m814=cat[cat.colnames[4]]\n",
    "dm814=cat[cat.colnames[5]]\n",
    "flag=cat[cat.colnames[6]]\n",
    "\n",
    "\n",
    "#CLEAN CATALOG\n",
    "#CUT ON ALL FLAGS *EXCEPT* BRIGHT NEIGHBORS (WHICH WOULD ELIMINATE ALL OF THE CLUSTER STARS)\n",
    "#ALSO ELIMINATE STARS FAINTER THAN 90% COMPLETENESS LIMIT AND TOO RED TO BE DWARF GALAXY MEMBERS\n",
    "good = ((flag & 1) == 0) & ((flag & 2) == 0) & ((flag & 4) == 0) & ((flag & 8) == 0) & ((flag & 1024) == 0) & (m814 < 29.15) & (m606 < 28.70) & (m606-m814 < 0)\n",
    "good_indices = [i for i, test in enumerate(good) if test]\n",
    "#OR good_indices = np.where(good)[0]\n",
    "xgood = x[good_indices]\n",
    "ygood = y[good_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11983"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xgood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BEGIN DEFINITION OF A MASK DESCRIBING THE PORTIONS OF THE IMAGE IN WHICH THERE IS DATA\n",
    "\n",
    "#IMAGE BOUNDARY\n",
    "IMAGE = Path([ [406,2390],\n",
    "              [2190,7814],\n",
    "              [7662,5536],\n",
    "              [5704,5],\n",
    "              [406,2390]])\n",
    "\n",
    "#ACS CHIP GAP\n",
    "GAP = Path([ [4842, 6714],\n",
    "             [4905, 6686],\n",
    "             [3037, 1208],\n",
    "             [2977, 1233],\n",
    "             [4842, 6714]])\n",
    "\n",
    "IMG_BIT = 0b01\n",
    "GAP_BIT = 0b10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINE A GRID OF 30X30 PIXEL BINS COVERING THE IMAGE\n",
    "NBINS = 268\n",
    "XMIN,XMAX = 0,8010\n",
    "YMIN,YMAX = 0,8010\n",
    "XEDGE = np.linspace(XMIN,XMAX,NBINS)\n",
    "YEDGE = np.linspace(XMIN,XMAX,NBINS)\n",
    "\n",
    "#BIN CENTERS\n",
    "XCENT = (XEDGE[1:] + XEDGE[:-1])/2.\n",
    "YCENT = (YEDGE[1:] + YEDGE[:-1])/2.\n",
    "#BIN SIZE\n",
    "XDEL = XEDGE[1]-XEDGE[0]\n",
    "YDEL = YEDGE[1]-YEDGE[0]\n",
    "\n",
    "# Pre-calculate these instead of doing it in each evaluation of the model...\n",
    "XX,YY= np.meshgrid(XCENT,YCENT,indexing='ij')\n",
    "\n",
    "\n",
    "#USE THE MASKED REGIONS FROM ABOVE TO CREATE AN IMAGE MASK WITH THE APPROPRIATE BINNING\n",
    "#REQUIRES FLATTENING THE ARRAYS\n",
    "MASK = np.zeros((NBINS-1,NBINS-1))\n",
    "image_mask = IMAGE.contains_points(np.vstack([XX.flatten(),YY.flatten()]).T).T.reshape(XX.shape)\n",
    "gap_mask = GAP.contains_points(np.vstack([XX.flatten(),YY.flatten()]).T).T.reshape(XX.shape)\n",
    "masked_indices_image = np.where(image_mask==1) # Array indices\n",
    "masked_indices_gap = np.where(gap_mask==1) # Array indices\n",
    "MASK[masked_indices_image] = 1\n",
    "MASK[masked_indices_gap] = 0\n",
    "IDX = np.where(MASK==1)\n",
    "\n",
    "#DISPLAY THE MASK TO CHECK THAT IT'S CORRECT\n",
    "plt.imshow(MASK.T,origin='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #ADD HIGHLY SATURATED STAR IN THE WEST TO MASK\n",
    "# satstar_xcen = 2267\n",
    "# satstar_ycen = 813\n",
    "# near_satstar = np.where( np.sqrt((XX - satstar_xcen)**2 + (YY - satstar_ycen)**2) < 84)\n",
    "\n",
    "# DIFF_SPIKES_EW = Path([ [1862, 829], \n",
    "# \t[1862, 823], \n",
    "# \t[2640, 823], \n",
    "# \t[2640, 829], \n",
    "# \t[1862, 829]])\n",
    "\n",
    "# DIFF_SPIKES_NS = Path([ [2263, 1183], \n",
    "#     [2250, 501], \n",
    "# \t[2264, 492], \n",
    "# \t[2276, 1178], \n",
    "# \t[2263, 1183]])\n",
    "\n",
    "# MASK[near_satstar] = 0\n",
    "\n",
    "# spikes_mask_ew = DIFF_SPIKES_EW.contains_points(np.vstack([XX.flatten(),YY.flatten()]).T).T.reshape(XX.shape)\n",
    "# masked_indices_spikes_ew = np.where(spikes_mask_ew==1) # Array indices\n",
    "# MASK[masked_indices_spikes_ew] = 0\n",
    "\n",
    "# spikes_mask_ns = DIFF_SPIKES_NS.contains_points(np.vstack([XX.flatten(),YY.flatten()]).T).T.reshape(XX.shape)\n",
    "# masked_indices_spikes_ns = np.where(spikes_mask_ns==1) # Array indices\n",
    "# MASK[masked_indices_spikes_ns] = 0\n",
    "# plt.imshow(MASK.T,origin='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINE INITIAL MODEL PARAMETERS FOR ERI II\n",
    "ERI_NSTAR = 28000 \n",
    "#ERI_LON = 56.0888               # RA (deg)\n",
    "#ERI_LAT = -43.5304              # Dec (deg)\n",
    "ERI_X0 = 4000                    # X Center (pix)\n",
    "ERI_Y0 = 3700                    # Y Center (pix)\n",
    "ERI_EXT = 2.31/60.               # Extension (deg) # radius in arcminutes\n",
    "ERI_EXT_PIX = 4000               # Extension (pix)\n",
    "ERI_ELL = 0.41                   # Ellipticity\n",
    "ERI_PA = 72.6                    # Position angle (deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINE INITIAL MODEL PARAMETERS FOR SECOND COMPONENT (CENTRAL CLUSTER IN THE CASE OF ERI II)\n",
    "CLUSTER_NSTAR = 500  # Richness (number of stars)\n",
    "CLUSTER_X0 = 3700                        # X Center (pix)\n",
    "CLUSTER_Y0 = 3600                        # Y Center (pix)\n",
    "CLUSTER_EXT = 7.67/3600.                 # Extension (deg)\n",
    "CLUSTER_EXT_PIX = 300                    # Extension (pix)\n",
    "CLUSTER_ELL = 0.30                       # Ellipticity\n",
    "CLUSTER_PA = 75.                         # Position angle (deg)\n",
    "CLUSTER_N = 0.41                         # Sersic index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_interval(data, alpha=0.32):\n",
    "    \"\"\"\n",
    "    Median including Bayesian credible interval.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data  : posterior samples\n",
    "    alpha : 1 - confidence interval\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    [med,[lo, hi]] : median, lower, and upper percentiles\n",
    "    \n",
    "    \"\"\"\n",
    "    q = [100*alpha/2., 50, 100*(1-alpha/2.)]\n",
    "    lo,med,hi = np.percentile(data,q)\n",
    "    return [med,[lo,hi]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data(x,y):\n",
    "    \"\"\" Calculate the binned data counts. This only needs to be done\n",
    "    once (not at each model evaluation), but this seemed easier to\n",
    "    understand if it paralleled the model counts calculation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : the x coordinate of the data\n",
    "    y : the y coordinate of the data\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data_counts : the data counts in each bin\n",
    "    \"\"\"\n",
    "    data_counts,_,_ = np.histogram2d(x,y,bins=[XEDGE,YEDGE])\n",
    "    return data_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_kernel(x,y,lon=ERI_X0,lat=ERI_Y0,ext=ERI_EXT_PIX,ell=ERI_ELL,pa=ERI_PA):\n",
    "    \"\"\" Evaluate the elliptical exponential kernel at coordinates x,y. \n",
    "    Normalized to unity over all space...\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: x-coord for evaluating kernel [pix]\n",
    "    y: y-coord for evaluating kernel [pix]\n",
    "    lon: x-coord of kernel centroid [pix]\n",
    "    lat: y-coord of kernel centroid [pix]\n",
    "    ext: extension [pix]\n",
    "    ell: ellipticity\n",
    "    pa:  position angle [deg]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pdf : probability density (should integrate to unity over all space)\n",
    "    \"\"\"\n",
    "\n",
    "    # Elliptical radius of each x,y coord\n",
    "    costh = np.cos(np.radians(-pa))\n",
    "    sinth = np.sin(np.radians(-pa))\n",
    "    dx = x-lon\n",
    "    dy = y-lat\n",
    "    radius = np.sqrt(((dx*costh-dy*sinth)/(1-ell))**2 + (dx*sinth+dy*costh)**2)\n",
    "\n",
    "    # Exponential radius (re = rh/1.68)\n",
    "    r_e = ext/1.68 \n",
    "    #Normalization (integrates to unity over all space) [stars/pix^2)\n",
    "    norm = 1./(2*np.pi*r_e**2 * (1-ell) )\n",
    "\n",
    "    # Exponential PDF\n",
    "    pdf = norm * np.exp(-radius/r_e)\n",
    "\n",
    "    return pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_kernel_plummer(x,y,lon=ERI_X0,lat=ERI_Y0,ext=ERI_EXT_PIX,ell=ERI_ELL,pa=ERI_PA):\n",
    "    \"\"\" Evaluate the elliptical Plummer kernel at coordinates x,y. \n",
    "    Normalized to unity over all space...\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: x-coord for evaluating kernel [pix]\n",
    "    y: y-coord for evaluating kernel [pix]\n",
    "    lon: x-coord of kernel centroid [pix]\n",
    "    lat: y-coord of kernel centroid [pix]\n",
    "    ext: extension [pix]\n",
    "    ell: ellipticity\n",
    "    pa:  position angle [deg]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pdf : probability density (should integrate to unity over all space)\n",
    "    \"\"\"\n",
    "\n",
    "    # Elliptical radius of each x,y coord\n",
    "    costh = np.cos(np.radians(-pa))\n",
    "    sinth = np.sin(np.radians(-pa))\n",
    "    dx = x-lon\n",
    "    dy = y-lat\n",
    "    radius = np.sqrt(((dx*costh-dy*sinth)/(1-ell))**2 + (dx*sinth+dy*costh)**2)\n",
    "\n",
    "    #PLUMMER SCALE RADIUS = HALF-LIGHT RADIUS \n",
    "    r_e = ext\n",
    "    #Normalization (integrates to unity over all space?) [stars/pix^2)\n",
    "    norm = r_e**2/(np.pi*(1-ell))\n",
    "\n",
    "    # Plummer PDF\n",
    "    pdf = norm / ((radius**2 + r_e**2)**2)\n",
    "\n",
    "    return pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(theta_eri2):\n",
    "    \"\"\" Calculate the binned model counts. This extends over the\n",
    "    entire pixel range, but we will apply the mask later.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    theta : the model parameters\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    model_counts : the model counts in each bin\n",
    "    \"\"\"\n",
    "    #FIT ALL MODEL PARAMETERS\n",
    "    richness = theta_eri2[0]\n",
    "    kwargs = dict(lon=theta_eri2[1],lat=theta_eri2[2],ext=theta_eri2[3],ell=theta_eri2[4],pa=theta_eri2[5])\n",
    "    #THIS CAN BE USED TO HOLD SOME OF THE PARAMETERS FIXED\n",
    "    # Default values for the other parameters\n",
    "    #kwargs.update(ext=ERI_EXT_PIX,ell=ERI_ELL)\n",
    "\n",
    "    #CHANGE KERNEL CALLED HERE TO USE A DIFFERENT FUNCTIONAL FORM FOR THE SURFACE DENSITY OF THE GALAXY\n",
    "    # The new kernel in pixel coordinates\n",
    "    pdf = new_kernel_plummer(XX,YY,**kwargs)\n",
    "\n",
    "    # Calculate the model predicted counts in each pixel\n",
    "    pixarea = XDEL*YDEL\n",
    "    model_counts = richness * pdf * pixarea\n",
    "    return model_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_kernel_cluster(x,y,lon=CLUSTER_X0,lat=CLUSTER_Y0,ext=CLUSTER_EXT_PIX,ell=CLUSTER_ELL,pa=CLUSTER_PA):\n",
    "    \"\"\" Evaluate the elliptical exponential kernel for the second component [cluster] at coordinates x,y. \n",
    "    Normalized to unity over all space...\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: x-coord for evaluating kernel [pix]\n",
    "    y: y-coord for evaluating kernel [pix]\n",
    "    lon: x-coord of kernel centroid [pix]\n",
    "    lat: y-coord of kernel centroid [pix]\n",
    "    ext: extension [pix]\n",
    "    ell: ellipticity\n",
    "    pa:  position angle [deg]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pdf : probability density (should integrate to unity over all space)\n",
    "    \"\"\"\n",
    "\n",
    "    # Elliptical radius of each x,y coord\n",
    "    costh = np.cos(np.radians(-pa))\n",
    "    sinth = np.sin(np.radians(-pa))\n",
    "    dx = x-lon\n",
    "    dy = y-lat\n",
    "    radius = np.sqrt(((dx*costh-dy*sinth)/(1-ell))**2 + (dx*sinth+dy*costh)**2)\n",
    "\n",
    "    # Exponential radius (re = rh/1.68)\n",
    "    r_e = ext/1.68 \n",
    "    #Normalization (integrates to unity over all space) [stars/pix^2)\n",
    "    norm = 1./(2*np.pi*r_e**2 * (1-ell) )\n",
    "\n",
    "    # Exponential PDF\n",
    "    pdf = norm * np.exp(-radius/r_e)\n",
    "\n",
    "    return pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_kernel_cluster_plummer(x,y,lon=CLUSTER_X0,lat=CLUSTER_Y0,ext=CLUSTER_EXT_PIX,ell=CLUSTER_ELL,pa=CLUSTER_PA):\n",
    "    \"\"\" Evaluate the elliptical Plummer kernel for the second component [cluster] at coordinates x,y. \n",
    "    Normalized to unity over all space...\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: x-coord for evaluating kernel [pix]\n",
    "    y: y-coord for evaluating kernel [pix]\n",
    "    lon: x-coord of kernel centroid [pix]\n",
    "    lat: y-coord of kernel centroid [pix]\n",
    "    ext: extension [pix]\n",
    "    ell: ellipticity\n",
    "    pa:  position angle [deg]\n",
    "#    bg:  surface density of non-cluster stars [pix^-2]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pdf : probability density (should integrate to unity over all space)\n",
    "    \"\"\"\n",
    "\n",
    "    # Elliptical radius of each x,y coord\n",
    "    costh = np.cos(np.radians(-pa))\n",
    "    sinth = np.sin(np.radians(-pa))\n",
    "    dx = x-lon\n",
    "    dy = y-lat\n",
    "    radius = np.sqrt(((dx*costh-dy*sinth)/(1-ell))**2 + (dx*sinth+dy*costh)**2)\n",
    "\n",
    "    #PLUMMER SCALE RADIUS = HALF-LIGHT RADIUS \n",
    "    r_e = ext\n",
    "    #Normalization (integrates to unity over all space?) [stars/pix^2)\n",
    "    norm = r_e**2/(np.pi*(1-ell))\n",
    "\n",
    "    # Plummer PDF\n",
    "    pdf = norm / ((radius**2 + r_e**2)**2)\n",
    "\n",
    "    return pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_kernel_cluster_sersic(x,y,lon=CLUSTER_X0,lat=CLUSTER_Y0,nserc=CLUSTER_N,ext=CLUSTER_EXT_PIX,ell=CLUSTER_ELL,pa=CLUSTER_PA):\n",
    "    \"\"\" Evaluate the elliptical Sersic kernel for the second component [cluster] at coordinates x,y. \n",
    "    Normalized to unity over all space...\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: x-coord for evaluating kernel [pix]\n",
    "    y: y-coord for evaluating kernel [pix]\n",
    "    lon: x-coord of kernel centroid [pix]\n",
    "    lat: y-coord of kernel centroid [pix]\n",
    "    ext: extension [pix]\n",
    "    ell: ellipticity\n",
    "    pa:  position angle [deg]\n",
    "    nserc: Sersic index\n",
    "#    bg:  surface density of non-cluster stars [pix^-2]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pdf : probability density (should integrate to unity over all space)\n",
    "    \"\"\"\n",
    "\n",
    "    # Elliptical radius of each x,y coord\n",
    "    costh = np.cos(np.radians(-pa))\n",
    "    sinth = np.sin(np.radians(-pa))\n",
    "    dx = x-lon\n",
    "    dy = y-lat\n",
    "    radius = np.sqrt(((dx*costh-dy*sinth)/(1-ell))**2 + (dx*sinth+dy*costh)**2)\n",
    "\n",
    "    #Normalization (integrates to unity over all space) [stars/pix^2)\n",
    "    #I_e = 5*(b_0.3)^0.6*e^(-b_0.3)/(3*pi*(1-ell)*r_h^2*Gamma(0.6))\n",
    "    #Calculate b_n from Gamma(2n) = 2*igamma(2n,b_n)\n",
    "\n",
    "    #SERSIC SCALE RADIUS = HALF-LIGHT RADIUS \n",
    "    r_h = ext\n",
    "    #ONLY VALID FOR N=0.41\n",
    "#     norm = 0.753/(np.pi * r_h**2 * (1-ell) )\n",
    "    \n",
    "    #Sersic PDF\n",
    "#     pdf = norm * np.exp(-0.6531*(radius/r_h)**(1/nserc))\n",
    "    \n",
    "    norm = 0.6247/(np.pi * r_h**2 * (1-ell) )\n",
    "\n",
    "     #Sersic PDF\n",
    "    pdf = norm * np.exp(-0.52033*(radius/r_h)**(1/nserc))\n",
    "\n",
    "    return pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_cluster(theta_cluster):\n",
    "    \"\"\" Calculate the binned model counts. This extends over the\n",
    "    entire pixel range, but we will apply the mask later.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    theta : the model parameters\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    model_counts : the model counts in each bin\n",
    "    \"\"\"\n",
    "\n",
    "    #FIT ALL MODEL PARAMETERS    \n",
    "    richness = theta_cluster[0]\n",
    "    kwargs = dict(lon=theta_cluster[1],lat=theta_cluster[2],ext=theta_cluster[3],ell=theta_cluster[4],pa=theta_cluster[5])\n",
    "    #THIS CAN BE USED TO HOLD SOME OF THE PARAMETERS FIXED\n",
    "    # Default values for the other parameters\n",
    "    #kwargs.update(ext=CLUSTER_EXT_PIX,ell=CLUSTER_ELL,pa=CLUSTER_PA)\n",
    "\n",
    "    #CHANGE KERNEL CALLED HERE TO USE A DIFFERENT FUNCTIONAL FORM FOR THE SURFACE DENSITY OF THE SECOND COMPONENT [CLUSTER]\n",
    "    # The new kernel in pixel coordinates\n",
    "    pdf = new_kernel_cluster_sersic(XX,YY,**kwargs)\n",
    "\n",
    "    # Calculate the model predicted counts in each pixel\n",
    "    pixarea = XDEL*YDEL\n",
    "    model_counts_cluster = richness * pdf * pixarea\n",
    "    return model_counts_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnlike(theta, x, y):\n",
    "    \"\"\" Likelihood function\n",
    "    Parameters\n",
    "    ----------\n",
    "    theta : model parameter array (richness,lon,lat,ext,ell,pa)x2\n",
    "    x: x-coordinate of data\n",
    "    y: y-coordinate of data\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    lnlike: log-likelihood\n",
    "    \"\"\"\n",
    "\n",
    "    #BREAK THETA UP INTO ERI II AND CLUSTER COMPONENTS\n",
    "    #IF ONLY ONE COMPONENT IS BEING FIT, THEN THESE LINES ARE NOT NEEDED\n",
    "    theta_eri2 = theta[:6]\n",
    "    \n",
    "    #commenting out to see if this will run\n",
    "    theta_cluster = theta[6:]\n",
    "    \n",
    "    # Calculate the data counts and model predicted counts in each pixel bin\n",
    "    data_counts = data(x,y)\n",
    "    model_counts_eri2 = model(theta_eri2)\n",
    "    \n",
    "    #ditto\n",
    "    model_counts_cluster = model_cluster(theta_cluster)\n",
    "    #TO FIT A SINGLE COMPONENT, USE, E.G., MODEL_COUNTS = MODEL_COUNTS_ERI2\n",
    "    model_counts = model_counts_eri2 + model_counts_cluster\n",
    "\n",
    "    # Apply the mask to the data and model. This selects only pixels\n",
    "    # in the image for calculating the likelihood.\n",
    "    data_counts_masked = data_counts[IDX]\n",
    "    model_counts_masked = model_counts[IDX]\n",
    "    \n",
    "    # Evaluate Equation C2 from Drlica-Wagner et al. 2020 (1912.03302; ignore k! term)\n",
    "    lnlike = np.sum(-model_counts_masked + data_counts_masked * np.log(model_counts_masked))\n",
    "    return lnlike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnprior(theta):\n",
    "    \"\"\" The log-prior. Add whatever you want here... \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    theta : model parameters\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    lnprior : log-prior\n",
    "    \"\"\"\n",
    "    #PRIORS FOR EACH FITTED PARAMETER\n",
    "    #TO REMOVE ANY PARAMETER FROM THE FIT, REMOVE IT FROM THE LINE BELOW AND ELIMINATE THE CONSTRAINT FOR IT\n",
    "    \n",
    "    rich1,lon1,lat1,ext1,ell1,pa1,rich2,lon2,lat2,ext2,ell2,pa2 = theta[0],theta[1],theta[2],theta[3],theta[4],theta[5],theta[6],theta[7],theta[8],theta[9],theta[10],theta[11]\n",
    "\n",
    "    if not (5000 < rich1 < 40000):  return np.inf\n",
    "    if not (3000 < lon1 < 5000): return np.inf\n",
    "    if not (3000 < lat1 < 5000): return np.inf\n",
    "    if not (2000 < ext1 < 8000): return np.inf\n",
    "    if not (0.1 < ell1 < 0.9): return np.inf\n",
    "    if not (50 < pa1 < 90): return np.inf\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnprob(theta, x, y):\n",
    "    \"\"\" The log-probability = lnlike + lnprob \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    theta : the model parameter vector\n",
    "    x     : x-coord of the data\n",
    "    y     : y-coord of the data\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    lnprob : log-probability\n",
    "    \"\"\"\n",
    "    lp = lnprior(theta)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + lnlike(theta, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_counts = data(xgood,ygood)\n",
    "data_counts_masked = np.copy(data_counts)\n",
    "data_counts_masked[np.where(MASK==0)] = np.nan\n",
    "out_masked_counts = data_counts_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FLAG FOR DISPLAYING PLOTS\n",
    "do_plot=True\n",
    "save_plot=True\n",
    "\n",
    "#SET INITIAL GUESSES FOR PARAMETERS (ANY PARAMETERS NOT BEING FIT SHOULD BE REMOVED HERE)\n",
    "THETA = [ERI_NSTAR,ERI_X0,ERI_Y0,ERI_EXT_PIX,ERI_ELL,ERI_PA,CLUSTER_NSTAR,CLUSTER_X0,CLUSTER_Y0,CLUSTER_EXT_PIX,CLUSTER_ELL,CLUSTER_PA]\n",
    "\n",
    "\n",
    "#PLOT (MASKED, BINNED) OBSERVED SURFACE DENSITY\n",
    "if do_plot:\n",
    "    # Example of the masked counts and data\n",
    "    # (transpose due to difference between imshow and histogram2d...)\n",
    "    data_counts = data(xgood,ygood)\n",
    "    data_counts_masked = np.copy(data_counts)\n",
    "    data_counts_masked[np.where(MASK==0)] = np.nan\n",
    "    out_masked_counts = data_counts_masked\n",
    "    plt.imshow(data_counts_masked.T,origin='lower')\n",
    "    if save_plot:\n",
    "        plt.savefig('data_counts_masked.png')\n",
    "\n",
    "\n",
    "#VARIABLE TO HOLD FIT RESULTS\n",
    "results = []\n",
    "     \n",
    "# Initialize and run the mcmc\n",
    "print(\"Running mcmc...\")\n",
    "ndim, nwalkers = len(THETA), 100\n",
    "nthreads,nsamples = 16, 3000\n",
    "nburn = 1000\n",
    "pos = [THETA + 1e-4*np.random.randn(ndim) for i in range(nwalkers)]\n",
    "     \n",
    "sampler = emcee.EnsembleSampler(nwalkers,ndim,lnprob,args=(xgood,ygood),\n",
    "                                threads=nthreads)\n",
    "sampler.run_mcmc(pos,nsamples)\n",
    "     \n",
    "samples = sampler.chain[:, nburn:, :].reshape((-1, ndim))\n",
    "\n",
    "#MEDIAN VALUES AND +/-1 SIGMA FOR EACH FIT PARAMETER\n",
    "rich,[rich_min,rich_max] = median_interval(samples[:,0])\n",
    "x,[xmin,xmax] = median_interval(samples[:,1])\n",
    "y,[ymin,ymax] = median_interval(samples[:,2])\n",
    "eri2_ext_fit,[eri2_ext_min,eri2_ext_max] = median_interval(samples[:,3])\n",
    "eri2_ell_fit,[eri2_ell_min,eri2_ell_max] = median_interval(samples[:,4])\n",
    "eri2_pa_fit,[eri2_pa_min,eri2_pa_max] = median_interval(samples[:,5])\n",
    "\n",
    "rich_cluster,[rich_cluster_min,rich_cluster_max] = median_interval(samples[:,6])\n",
    "x_cluster,[x_cluster_min,x_cluster_max] = median_interval(samples[:,7])\n",
    "y_cluster,[y_cluster_min,y_cluster_max] = median_interval(samples[:,8])\n",
    "cluster_ext_fit,[cluster_ext_min,cluster_ext_max] = median_interval(samples[:,9])\n",
    "cluster_ell_fit,[cluster_ell_min,cluster_ell_max] = median_interval(samples[:,10])\n",
    "cluster_pa_fit,[cluster_pa_min,cluster_pa_max] = median_interval(samples[:,11])\n",
    "\n",
    "\n",
    "#POPULATE RESULTS ARRAY\n",
    "res = [rich,rich_min,rich_max,x,xmin,xmax,y,ymin,ymax,eri2_ext_fit,eri2_ext_min,\n",
    "       eri2_ext_max,eri2_ell_fit,eri2_ell_min,eri2_ell_max,eri2_pa_fit,eri2_pa_min,\n",
    "       eri2_pa_max,rich_cluster,rich_cluster_min,rich_cluster_max,x_cluster,\n",
    "       x_cluster_min,x_cluster_max,y_cluster,y_cluster_min,y_cluster_max,\n",
    "       cluster_ext_fit,cluster_ext_min,cluster_ext_max,cluster_ell_fit,\n",
    "       cluster_ell_min,cluster_ell_max,cluster_pa_fit,cluster_pa_min,cluster_pa_max]\n",
    "results.append(res)\n",
    "\n",
    "if do_plot:\n",
    "    theta_eri2 = [rich,x,y,eri2_ext_fit,eri2_ell_fit,eri2_pa_fit]\n",
    "    theta_cluster = [rich_cluster,x_cluster,y_cluster,cluster_ext_fit,cluster_ell_fit,cluster_pa_fit]\n",
    "    model_counts_eri2 = model(theta_eri2)\n",
    "    model_counts_cluster = model_cluster(theta_cluster)\n",
    "    model_counts = model_counts_eri2 + model_counts_cluster\n",
    "    model_counts_masked = np.copy(model_counts)\n",
    "    model_counts_masked[np.where(MASK==0)] = np.nan\n",
    "#PLOT (MASKED, BINNED) MODEL SURFACE DENSITY\n",
    "    plt.imshow(model_counts_masked.T,origin='lower')\n",
    "    if save_plot:\n",
    "        plt.savefig('model_counts_masked.png')\n",
    "\n",
    "#CORNER PLOT    \n",
    "    fig = corner.corner(samples, labels=[\"rich\", \"x\", \"y\", \"eri2_ext_fit\", \"eri2_ell_fit\", \n",
    "                                         \"eri2_pa_fit\",\"rich_cluster\", \"x_cluster\", \"y_cluster\", \n",
    "                                         \"cluster_ext_fit\", \"cluster_ell_fit\", \"cluster_pa_fit\"])\n",
    "    if save_plot:\n",
    "        fig.savefig(\"triangle0625.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To output result values\n",
    "results = np.rec.array(results,names=['rich','rich_min','rich_max','x','xmin','xmax','y','ymin','ymax',\\\n",
    "        'eri2_ext_fit','eri2_ext_min','eri2_ext_max','eri2_ell_fit','eri2_ell_min','eri2_ell_max','eri2_pa_fit',\\\n",
    "            'eri2_pa_min','eri2_pa_max','rich_cluster','rich_cluster_min','rich_cluster_max','x_cluster',\n",
    "        'x_cluster_min','x_cluster_max','y_cluster','y_cluster_min','y_cluster_max','cluster_ext_fit',\n",
    "        'cluster_ext_min','cluster_ext_max','cluster_ell_fit','cluster_ell_min','cluster_ell_max',\n",
    "                                      'cluster_pa_fit','cluster_pa_min','cluster_pa_max'])\n",
    "\n",
    "\n",
    "\n",
    "filename='results_b%i_s%i.csv'%(NBINS-1,nsamples)\n",
    "print(\"Writing %s ...\"%filename)\n",
    "rec2csv(results,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cPickle.dump(samples, open( \"eri2mcmc.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_surface_density_30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define annuli\n",
    "r1 = (radius < (0.1 * r_h)).nonzero()\n",
    "r2 = ((radius < (0.2 * r_h)) & (radius >= (0.1 * r_h))).nonzero()\n",
    "r3 = ((radius < (0.3 * r_h)) & (radius >= (0.2 * r_h))).nonzero()\n",
    "r4 = ((radius < (0.4 * r_h)) & (radius >= (0.3 * r_h))).nonzero()\n",
    "r5 = ((radius < (0.5 * r_h)) & (radius >= (0.4 * r_h))).nonzero()\n",
    "r6 = ((radius < (0.6 * r_h)) & (radius >= (0.5 * r_h))).nonzero()\n",
    "r7 = ((radius < (0.7 * r_h)) & (radius >= (0.6 * r_h))).nonzero()\n",
    "r8 = ((radius < (0.8 * r_h)) & (radius >= (0.7 * r_h))).nonzero()\n",
    "r9 = ((radius < (0.9 * r_h)) & (radius >= (0.8 * r_h))).nonzero()\n",
    "r10 = ((radius < r_h) & (radius >= (0.9 * r_h))).nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius < r_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra1 = np.arange(0,10,1)\n",
    "r_annuli = (ra1 + 0.05) * r_h\n",
    "\n",
    "area_annuli = np.pi * ((r_annuli + 0.05)**2 - (r_annuli - 0.05)**2)\n",
    "\n",
    "data_1d = [binned_surface_density_30[r1].sum(),\n",
    "           binned_surface_density_30[r2].sum(),\n",
    "           binned_surface_density_30[r3].sum(),\n",
    "           binned_surface_density_30[r4].sum(),\n",
    "           binned_surface_density_30[r5].sum(),\n",
    "           binned_surface_density_30[r6].sum(),\n",
    "           binned_surface_density_30[r7].sum(),\n",
    "           binned_surface_density_30[r8].sum(),\n",
    "           binned_surface_density_30[r9].sum(),\n",
    "           binned_surface_density_30[r10].sum()]\n",
    "\n",
    "model_1d = [model_counts_gal[r1].sum(),\n",
    "            model_counts_gal[r2].sum(),\n",
    "            model_counts_gal[r3].sum(),\n",
    "            model_counts_gal[r4].sum(),\n",
    "            model_counts_gal[r5].sum(),\n",
    "            model_counts_gal[r6].sum(),\n",
    "            model_counts_gal[r7].sum(),\n",
    "            model_counts_gal[r8].sum(),\n",
    "            model_counts_gal[r9].sum(),\n",
    "            model_counts_gal[r10].sum()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(ra1,data_1d,label='Data')\n",
    "ax.plot(ra1,model_1d,label='Model')\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #FLAG FOR DISPLAYING PLOTS\n",
    "# do_plot=True\n",
    "# save_plot=True\n",
    "\n",
    "# #SET INITIAL GUESSES FOR PARAMETERS (ANY PARAMETERS NOT BEING FIT SHOULD BE REMOVED HERE)\n",
    "# THETA = [ERI_NSTAR,ERI_X0,ERI_Y0,ERI_EXT_PIX,ERI_ELL,ERI_PA,CLUSTER_NSTAR,CLUSTER_X0,CLUSTER_Y0,CLUSTER_EXT_PIX,CLUSTER_ELL,CLUSTER_PA]\n",
    "\n",
    "\n",
    "# #PLOT (MASKED, BINNED) OBSERVED SURFACE DENSITY\n",
    "# if do_plot:\n",
    "#     # Example of the masked counts and data\n",
    "#     # (transpose due to difference between imshow and histogram2d...)\n",
    "#     data_counts = data(xgood,ygood)\n",
    "#     data_counts_masked = np.copy(data_counts)\n",
    "#     data_counts_masked[np.where(MASK==0)] = np.nan\n",
    "#     plt.imshow(data_counts_masked.T,origin='lower')\n",
    "#     if save_plot:\n",
    "#         plt.savefig('data_counts_masked.png')\n",
    "\n",
    "\n",
    "# #VARIABLE TO HOLD FIT RESULTS\n",
    "# results = []\n",
    "     \n",
    "# # Initialize and run the mcmc\n",
    "# print(\"Running mcmc...\")\n",
    "# ndim, nwalkers = len(THETA), 100\n",
    "# nthreads,nsamples = 16, 3000\n",
    "# nburn = 1000\n",
    "# pos = [THETA + 1e-4*np.random.randn(ndim) for i in range(nwalkers)]\n",
    "     \n",
    "# sampler = emcee.EnsembleSampler(nwalkers,ndim,lnprob,args=(xgood,ygood),\n",
    "#                                 threads=nthreads)\n",
    "# sampler.run_mcmc(pos,nsamples)\n",
    "     \n",
    "# samples = sampler.chain[:, nburn:, :].reshape((-1, ndim))\n",
    "\n",
    "# #MEDIAN VALUES AND +/-1 SIGMA FOR EACH FIT PARAMETER\n",
    "# rich,[rich_min,rich_max] = median_interval(samples[:,0])\n",
    "# x,[xmin,xmax] = median_interval(samples[:,1])\n",
    "# y,[ymin,ymax] = median_interval(samples[:,2])\n",
    "# eri2_ext_fit,[eri2_ext_min,eri2_ext_max] = median_interval(samples[:,3])\n",
    "# eri2_ell_fit,[eri2_ell_min,eri2_ell_max] = median_interval(samples[:,4])\n",
    "# eri2_pa_fit,[eri2_pa_min,eri2_pa_max] = median_interval(samples[:,5])\n",
    "\n",
    "# rich_cluster,[rich_cluster_min,rich_cluster_max] = median_interval(samples[:,6])\n",
    "# x_cluster,[x_cluster_min,x_cluster_max] = median_interval(samples[:,7])\n",
    "# y_cluster,[y_cluster_min,y_cluster_max] = median_interval(samples[:,8])\n",
    "# cluster_ext_fit,[cluster_ext_min,cluster_ext_max] = median_interval(samples[:,9])\n",
    "# cluster_ell_fit,[cluster_ell_min,cluster_ell_max] = median_interval(samples[:,10])\n",
    "# cluster_pa_fit,[cluster_pa_min,cluster_pa_max] = median_interval(samples[:,11])\n",
    "\n",
    "\n",
    "# #POPULATE RESULTS ARRAY\n",
    "# res = [rich,rich_min,rich_max,x,xmin,xmax,y,ymin,ymax,eri2_ext_fit,\\\n",
    "#        eri2_ext_min,eri2_ext_max,eri2_ell_fit,eri2_ell_min,\\\n",
    "#        eri2_ell_max,eri2_pa_fit,eri2_pa_min,eri2_pa_max,\\\n",
    "#        rich_cluster,rich_cluster_min,rich_cluster_max,x_cluster,\\\n",
    "#        x_cluster_min,x_cluster_max,y_cluster,y_cluster_min,\\\n",
    "#        y_cluster_max,cluster_ext_fit,cluster_ext_min,\\\n",
    "#        cluster_ext_max,cluster_ell_fit,cluster_ell_min,\\\n",
    "#        cluster_ell_max,cluster_pa_fit,cluster_pa_min,\\\n",
    "#        cluster_pa_max]\n",
    "# results.append(res)\n",
    "\n",
    "# if do_plot:\n",
    "#     theta_eri2 = [rich,x,y,eri2_ext_fit,eri2_ell_fit,eri2_pa_fit]\n",
    "#     theta_cluster = [rich_cluster,x_cluster,y_cluster,cluster_ext_fit,cluster_ell_fit,cluster_pa_fit]\n",
    "#     model_counts_eri2 = model(theta_eri2)\n",
    "#     model_counts_cluster = model_cluster(theta_cluster)\n",
    "#     model_counts = model_counts_eri2 + model_counts_cluster\n",
    "#     model_counts_masked = np.copy(model_counts)\n",
    "#     model_counts_masked[np.where(MASK==0)] = np.nan\n",
    "# #PLOT (MASKED, BINNED) MODEL SURFACE DENSITY\n",
    "#     plt.imshow(model_counts_masked.T,origin='lower')\n",
    "#     if save_plot:\n",
    "#         plt.savefig('model_counts_masked.png')\n",
    "\n",
    "# #CORNER PLOT    \n",
    "#     fig = corner.corner(samples, labels=[\"rich\", \"x\", \"y\", \"eri2_ext_fit\", \"eri2_ell_fit\", \"eri2_pa_fit\", \"rich_cluster\", \"x_cluster\", \"y_cluster\", \"cluster_ext_fit\", \"cluster_ell_fit\", \"cluster_pa_fit\"])\n",
    "#     if save_plot:\n",
    "#         fig.savefig(\"triangle0625.png\")\n",
    "\n",
    "# results = np.rec.array(results,names=['rich','rich_min','rich_max','x','xmin','xmax','y','ymin','ymax','eri2_ext_fit','eri2_ext_min','eri2_ext_max','eri2_ell_fit','eri2_ell_min','eri2_ell_max','eri2_pa_fit','eri2_pa_min','eri2_pa_max','rich_cluster','rich_cluster_min','rich_cluster_max','x_cluster','x_cluster_min','x_cluster_max','y_cluster','y_cluster_min','y_cluster_max','cluster_ext_fit','cluster_ext_min','cluster_ext_max','cluster_ell_fit','cluster_ell_min','cluster_ell_max','cluster_pa_fit','cluster_pa_min','cluster_pa_max'])\n",
    "\n",
    "# #numpy.core.records.array; Construct a record array from a wide-variety of objects.\n",
    "\n",
    "# filename='results_b%i_s%i.csv'%(NBINS-1,nsamples)\n",
    "# print(\"Writing %s ...\"%filename)\n",
    "# # rec2csv(results,filename)\n",
    "\n",
    "# # 5:24 5:45\n",
    "# # 5:48 - 6:03\n",
    "# # 6:46 - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='results_b%i_s%i_125p.csv'%(NBINS-1,nsamples)\n",
    "results.tofile(filename,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECK HOW LONG A BURN-IN IS NEEDED BEFORE FIT RESULTS STABILIZE\n",
    "for i in range(0,nwalkers-1):\n",
    "    plt.plot(sampler.chain[i,:,4],linewidth=1,color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXAMINE RESIDUALS NEAR THE CENTER OF THE GALAXY\n",
    "plt.imshow(model_counts.T*(1-gap_mask.T)-data_counts.T*(1-gap_mask.T),origin=\"lower\")\n",
    "plt.colorbar()\n",
    "plt.xlim(70,170)\n",
    "plt.ylim(70,170)\n",
    "plt.clim(-2.5,2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
